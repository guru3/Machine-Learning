{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try out tf-idf weighting! This involves term frequency and inverse document frequency.\n",
    "#### Term frequency increases the weight of the words that occur more frequently in the document i.e. tf( t, d ) indicates the number of occurrences of term 't' in doucment 'd'. However fifty occurences of a word in a document does not mean that the word is really fifty times more significant that any other word that occured just one, so we scale the values in logarithmic way.\n",
    "#### Inverse document frequency increases the weight of terms that occur rarely i.e. in few documents. Similarly it decreases the weight of terms that occur in all the documents. We define idf(t,D) as log( ( total number of documents in corpus D /  total documents with terms t in corpus D ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the movie sentiment corpus data\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "corpus_path = './corpus/' #this path needs to be changed depending on where your files lie\n",
    "sub_directories = [ 'pos', 'neg' ]\n",
    "\n",
    "def get_data():\n",
    "    all_docs = []\n",
    "    positive_ex = 0;\n",
    "    negative_ex = 0;\n",
    "    for subdir in sub_directories:\n",
    "        sentiment = corpus_path + subdir;\n",
    "        files = [ os.path.join(sentiment,f) for f in os.listdir(sentiment) ]\n",
    "        if( subdir == 'pos' ):\n",
    "            positive_ex = positive_ex + len( files )\n",
    "        else:\n",
    "            negative_ex = negative_ex + len( files )\n",
    "        for file in files:\n",
    "            doc = \"\";\n",
    "            for line in open( file, 'r' ):\n",
    "                doc = doc + line\n",
    "            all_docs.append( doc )\n",
    "    return [ positive_ex, negative_ex, all_docs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ positive_ex, negative_ex, all_docs ] = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min_df value 0 and max_df value 0.1, train accuracy is 98.11% and test accuracy is 81.8%\n",
      "For min_df value 0 and max_df value 0.3, train accuracy is 97.95% and test accuracy is 82.4%\n",
      "For min_df value 0 and max_df value 0.5, train accuracy is 97.85% and test accuracy is 82.7%\n",
      "For min_df value 0 and max_df value 0.7, train accuracy is 97.8% and test accuracy is 82.86%\n",
      "For min_df value 0 and max_df value 0.9, train accuracy is 97.76% and test accuracy is 82.94%\n",
      "For min_df value 0 and max_df value 0.999, train accuracy is 97.73% and test accuracy is 82.99%\n",
      "For min_df value 0.001 and max_df value 0.1, train accuracy is 97.65% and test accuracy is 82.9%\n",
      "For min_df value 0.001 and max_df value 0.3, train accuracy is 97.55% and test accuracy is 82.96%\n",
      "For min_df value 0.001 and max_df value 0.5, train accuracy is 97.45% and test accuracy is 83.0%\n",
      "For min_df value 0.001 and max_df value 0.7, train accuracy is 97.37% and test accuracy is 83.01%\n",
      "For min_df value 0.001 and max_df value 0.9, train accuracy is 97.3% and test accuracy is 83.02%\n",
      "For min_df value 0.001 and max_df value 0.999, train accuracy is 97.24% and test accuracy is 83.02%\n",
      "For min_df value 0.01 and max_df value 0.1, train accuracy is 96.86% and test accuracy is 83.01%\n",
      "For min_df value 0.01 and max_df value 0.3, train accuracy is 96.51% and test accuracy is 83.02%\n",
      "For min_df value 0.01 and max_df value 0.5, train accuracy is 96.21% and test accuracy is 83.03%\n",
      "For min_df value 0.01 and max_df value 0.7, train accuracy is 95.94% and test accuracy is 83.02%\n",
      "For min_df value 0.01 and max_df value 0.9, train accuracy is 95.7% and test accuracy is 83.02%\n",
      "For min_df value 0.01 and max_df value 0.999, train accuracy is 95.49% and test accuracy is 83.01%\n",
      "For min_df value 0.05 and max_df value 0.1, train accuracy is 94.87% and test accuracy is 82.75%\n",
      "For min_df value 0.05 and max_df value 0.3, train accuracy is 94.43% and test accuracy is 82.6%\n",
      "For min_df value 0.05 and max_df value 0.5, train accuracy is 94.02% and test accuracy is 82.5%\n",
      "For min_df value 0.05 and max_df value 0.7, train accuracy is 93.65% and test accuracy is 82.39%\n",
      "For min_df value 0.05 and max_df value 0.9, train accuracy is 93.31% and test accuracy is 82.3%\n",
      "For min_df value 0.05 and max_df value 0.999, train accuracy is 92.99% and test accuracy is 82.21%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "total_examples = positive_ex + negative_ex\n",
    "total_splits = 10\n",
    "\n",
    "labels = np.zeros(total_examples);\n",
    "labels[0:positive_ex] = 0;\n",
    "labels[positive_ex:total_examples] = 1;\n",
    "\n",
    "folds = StratifiedKFold( n_splits=total_splits )\n",
    "\n",
    "model = MultinomialNB()\n",
    "test_accuracy_h = [ 0.0, 0.0 ]\n",
    "train_accuracy_h = [ 0.0, 0.0 ]\n",
    "\n",
    "for min_df_val in [ 0, 0.001, 0.01, 0.05 ]:\n",
    "    for max_df_val in [ 0.1, 0.3, 0.5, 0.7, 0.9, 0.999 ]:\n",
    "        Vectorizer = TfidfVectorizer(\n",
    "            sublinear_tf=True, #change to log scale i.e change tf value to 1 + log(tf)\n",
    "            use_idf=True,      #use idf as well\n",
    "            stop_words='english', #filter out most common english words\n",
    "            min_df=min_df_val,  #ignore words that occurs in less than min_df proportion of documents\n",
    "            max_df=max_df_val, #ignore words that occurs a lot! i.e. in max_df proportion of documents\n",
    "            )\n",
    "        for train_indices, test_indices in folds.split(all_docs, labels):\n",
    "            docs_train = [ all_docs[ index ] for index in train_indices ]\n",
    "            docs_test  = [ all_docs[ index ] for index in test_indices ]\n",
    "            Y_train = labels[ train_indices ]\n",
    "            Y_test  = labels[ test_indices ]\n",
    "            X_train = Vectorizer.fit_transform(docs_train) \n",
    "            X_test = Vectorizer.transform(docs_test) \n",
    "\n",
    "            model.fit( X_train, Y_train )\n",
    "            train_result = model.predict( X_train )\n",
    "            test_result = model.predict( X_test )\n",
    "\n",
    "            train_accuracy_h[0] = train_accuracy_h[0] + sum( train_result==Y_train )\n",
    "            test_accuracy_h[0] = test_accuracy_h[0] + sum( test_result==Y_test )\n",
    "            train_accuracy_h[1] = train_accuracy_h[1] + len( train_result )\n",
    "            test_accuracy_h[1] = test_accuracy_h[1] + len( test_result )\n",
    "\n",
    "        train_acc = (train_accuracy_h[0]*100)/train_accuracy_h[1]    \n",
    "        test_acc = (test_accuracy_h[0]*100)/test_accuracy_h[1]\n",
    "        print('For min_df value {} and max_df value {}, train accuracy is {}% and test accuracy is {}%'.format(\n",
    "                min_df_val, max_df_val, round(train_acc, 2 ), round(test_acc, 2 )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we increase min_df value we see reduction in train_accuracy ( in our case ) but mixed trend for test accuracy. As we increase max_df value, we see reduction in train_accuracy, but in general increase in test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
